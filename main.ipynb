{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Assistant\n",
    "\n",
    "This is an LLM-powered search assistant that can help you find the most relevant searching keywords for searching in Google, based on your description of the problem.\n",
    "\n",
    "To run this script, read `Readme.md` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN is set in the environment variables.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load the .env file\n",
    "dotenv.load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# Check if \"HF_TOKEN\" is set in the environment variables\n",
    "if os.getenv(\"HF_TOKEN\") is None or os.getenv(\"HF_TOKEN\") == \"\":\n",
    "    # Ask the user to set the \"HF_TOKEN\" environment variable\n",
    "    os.environ[\"HF_TOKEN\"] = input(\"Please set the HF_TOKEN environment variable.\")\n",
    "    print(\"HF_TOKEN is set from user input.\")\n",
    "\n",
    "else:\n",
    "    print(\"HF_TOKEN is set in the environment variables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma2:2b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an AI assistant. Given the following user's description, you need to come up with a list of at least 10 relevant keywords than can be helpful for the user to search on Google to obtain relavant information and achieve what he/she wants. Search keywords can be single words or phrases.\"),\n",
    "        (\"human\", \"{description}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "llm_answer = chain.invoke({\n",
    "    \"description\": \"ÊàëÊÉ≥Ë¶ÅÂÅö‰∏™Â∑ßÂÖãÂäõËõãÁ≥ï„ÄÇ\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some keywords for a chocolate cake recipe:\n",
       "\n",
       "**General:**\n",
       "\n",
       "* Chocolate cake recipe \n",
       "* Easy chocolate cake\n",
       "* Best chocolate cake recipe \n",
       "* Chocolate cake ingredients\n",
       "* Homemade chocolate cake\n",
       "\n",
       "**Specific Flavors/Styles:**\n",
       "\n",
       "* **Chocolate fudge cake:**  If the user wants a dense, fudgy texture.\n",
       "* **Dark chocolate cake:** If the user wants a more intense chocolate flavor.\n",
       "* **White chocolate cake:**  If the user wants a sweeter option.\n",
       "* **Marble chocolate cake:** For adding contrasting flavors and textures. \n",
       "* **Ganache frosting:**  If the user is interested in a decadent, smooth icing.\n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "* **Chocolate cake for beginners:** If the user wants a recipe that's simple to follow.\n",
       "* **Chocolate cake gluten-free:**  For dietary restrictions. \n",
       "* **Moist chocolate cake:** For a specific texture preference.\n",
       "\n",
       "\n",
       "Let me know if you have any other information about what kind of recipe the user is looking for, and I can suggest more specific keywords! üç∞ üç´ \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(llm_answer.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
